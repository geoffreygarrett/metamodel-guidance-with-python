{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ggarrett/Repositories/NB10422645\n"
     ]
    }
   ],
   "source": [
    "%cd ~/Repositories/NB10422645/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.dataset import *\n",
    "from src.problems.two_dimensional.representation import NOmegaPointsScaleBasedPeriodic\n",
    "\n",
    "def convert_rotational_eom_to_solution_series(ds, init_theta, n_t_samples, reference_time, save_parquet=True):\n",
    "    mapping = NOmegaPointsScaleBasedPeriodic(n_samples=n_t_samples, n_design_points=3, init_theta=init_theta)\n",
    "    \n",
    "    df = ds.get_df()\n",
    "    x_col = list(filter(lambda x: 'x' in x, df.columns))\n",
    "    f_col = list(filter(lambda x: 'f' in x, df.columns))\n",
    "\n",
    "    x_df = ds.get_df().loc[:,x_col]\n",
    "    f_df = ds.get_df().loc[:,f_col]\n",
    "\n",
    "    n_t_samples = n_t_samples\n",
    "    n_samples = x_df.index.size\n",
    "    mapping.reference_time = reference_time\n",
    "\n",
    "    alpha_samples = np.zeros((n_samples,n_t_samples))\n",
    "    omega_samples = np.zeros((n_samples,n_t_samples))\n",
    "    theta_samples = np.zeros((n_samples,n_t_samples))\n",
    "\n",
    "    for idx, row in x_df.iterrows():\n",
    "        print(idx) if idx%100000==0 else None\n",
    "        alpha_sample, omega_sample, theta_sample = mapping(row.values)\n",
    "        alpha_samples[idx,:] = alpha_sample\n",
    "        omega_samples[idx,:] = omega_sample\n",
    "        theta_samples[idx,:] = theta_sample\n",
    "\n",
    "    time_column = [f\"t{i}\" for i in range(n_t_samples)]\n",
    "    dataframe_alpha = pd.DataFrame(data=alpha_samples, columns=time_column)\n",
    "    dataframe_omega = pd.DataFrame(data=omega_samples, columns=time_column)\n",
    "    dataframe_theta = pd.DataFrame(data=theta_samples, columns=time_column)\n",
    "    \n",
    "    ds_alpha = DataSetFX(output=f_df.values, input=dataframe_alpha.values, name=ds.name+\"_series_alpha\", root_dir=\"data\")\n",
    "    ds_omega = DataSetFX(output=f_df.values, input=dataframe_omega.values, name=ds.name+\"_series_omega\", root_dir=\"data\")\n",
    "    ds_theta = DataSetFX(output=f_df.values, input=dataframe_theta.values, name=ds.name+\"_series_theta\", root_dir=\"data\")\n",
    "    \n",
    "    if save_parquet:\n",
    "        ds_alpha.to_parquet(file_name=ds.name+\"_series_alpha\", root_dir=\"data\")\n",
    "        ds_omega.to_parquet(file_name=ds.name+\"_series_omega\", root_dir=\"data\")\n",
    "        ds_theta.to_parquet(file_name=ds.name+\"_series_theta\", root_dir=\"data\")\n",
    "        \n",
    "    return ds_alpha, ds_omega, ds_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2187\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "ds = DataSetFX.from_parquet(root_dir=\"data\", file_name=\"dataSet_gridSampled_3.parquet\")\n",
    "print(len(ds))\n",
    "\n",
    "reference_time = 6529.276071694349\n",
    "n_t_samples = 652\n",
    "init_theta = -3.141592653589793\n",
    "\n",
    "ds_alpha, ds_omega, ds_theta = convert_rotational_eom_to_solution_series(ds, init_theta, n_t_samples, reference_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Args:\n",
    "- in_channels (int): Number of channels in the input image\n",
    "- out_channels (int): Number of channels produced by the convolution\n",
    "- kernel_size (int or tuple): Size of the convolving kernel\n",
    "- stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
    "- padding (int or tuple, optional): Zero-padding added to both sides of the input. Default: 0\n",
    "- padding_mode (string, optional). Accepted values `zeros` and `circular` Default: `zeros`\n",
    "- dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
    "- groups (int, optional): Number of blocked connections from input channels to output channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.surrogate.modules import *\n",
    "from src.surrogate.deeplearning.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test case 1\n",
    "\n",
    "transform\n",
    "\n",
    "Data:\n",
    "- F = F, X = Theta\n",
    "- \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "transform = TransformDataFrame.from_ordered_dict(OrderedDict([\n",
    "    (\"tf1\", (preprocessing.MinMaxScaler(feature_range=(0, 1)), [\"f1\", \"f2\", \"f3\", \"f4\"]))\n",
    "#     (\"tx1\", (preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True), [f\"x{i}\" for i in range(652)])),\n",
    "]\n",
    "))\n",
    "\n",
    "ds_t1_theta = DataSetFSeries.from_parquet(root_dir=\"data\", file_name=\"dataSet_gridSampled_6_series_theta\", transform=transform)\n",
    "\n",
    "# Define training function.\n",
    "def train_model(name, ds, model, model_folder, load=False):\n",
    "    trainer = Trainer(model_folder, ds, model, torch.optim.Adam, torch.nn.L1Loss, num_epochs=50, batch_size=int(2e4), learning_rate=1e-3)\n",
    "#     trainer.add_scheduler(torch.optim.lr_scheduler.MultiStepLR, milestones=[10], gamma=0.1)\n",
    "    if load:\n",
    "        trainer.load_checkpoint(model_folder)\n",
    "    trainer.train()\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1, 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Interrupted\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ggarrett/anaconda3/envs/sigh/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "name = \"experiment1_series\"\n",
    "folder = f\"models/{name}\"\n",
    "\n",
    "ds = ds_t1_theta\n",
    "\n",
    "model1 = nn.Sequential(\n",
    "    BasicBlock(input_size=1, output_size=100, kernel_size=(1, 109)),\n",
    "    torch.nn.MaxPool2d((1, 109), stride=1, padding=0, dilation=1, return_indices=False, ceil_mode=False),\n",
    "    BasicBlock(input_size=100, output_size=10, kernel_size=(1, 109)),\n",
    "    Flatten(),\n",
    "    RegressionOutput(3280, 4)\n",
    ")\n",
    "\n",
    "train_model(name, ds, model1, folder, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sigh",
   "language": "python",
   "name": "sigh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
