{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ggarrett/lab/NB10422645 (Stage - Airbus)\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ggarrett/lab/NB10422645\\ \\(Stage\\ -\\ Airbus\\)\n",
    "                                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.dataset import *\n",
    "from src.problems.two_dimensional.representation import NOmegaPointsScaleBasedPeriodic\n",
    "\n",
    "def convert_rotational_eom_to_solution_series(ds, init_theta, n_t_samples, reference_time, save_parquet=True):\n",
    "    mapping = NOmegaPointsScaleBasedPeriodic(n_samples=n_t_samples, n_design_points=3, init_theta=init_theta)\n",
    "    \n",
    "    df = ds.get_df()\n",
    "    x_col = list(filter(lambda x: 'x' in x, df.columns))\n",
    "    f_col = list(filter(lambda x: 'f' in x, df.columns))\n",
    "\n",
    "    x_df = ds.get_df().loc[:,x_col]\n",
    "    f_df = ds.get_df().loc[:,f_col]\n",
    "\n",
    "    n_t_samples = n_t_samples\n",
    "    n_samples = x_df.index.size\n",
    "    mapping.reference_time = reference_time\n",
    "\n",
    "    alpha_samples = np.zeros((n_samples,n_t_samples))\n",
    "    omega_samples = np.zeros((n_samples,n_t_samples))\n",
    "    theta_samples = np.zeros((n_samples,n_t_samples))\n",
    "\n",
    "    for idx, row in x_df.iterrows():\n",
    "        print(idx) if idx%100000==0 else None\n",
    "        alpha_sample, omega_sample, theta_sample = mapping(row.values)\n",
    "#         alpha_samples[idx,:] = alpha_sample\n",
    "        omega_samples[idx,:] = omega_sample\n",
    "#         theta_samples[idx,:] = theta_sample\n",
    "\n",
    "    time_column = [f\"t{i}\" for i in range(n_t_samples)]\n",
    "    dataframe_alpha = pd.DataFrame(data=alpha_samples, columns=time_column)\n",
    "    dataframe_omega = pd.DataFrame(data=omega_samples, columns=time_column)\n",
    "    dataframe_theta = pd.DataFrame(data=theta_samples, columns=time_column)\n",
    "    \n",
    "    ds_alpha = DataSetFX(output=f_df.values, input=dataframe_alpha.values, name=ds.name+\"_series_alpha\", root_dir=\"data\")\n",
    "    ds_omega = DataSetFX(output=f_df.values, input=dataframe_omega.values, name=ds.name+\"_series_omega\", root_dir=\"data\")\n",
    "    ds_theta = DataSetFX(output=f_df.values, input=dataframe_theta.values, name=ds.name+\"_series_theta\", root_dir=\"data\")\n",
    "    \n",
    "    if save_parquet:\n",
    "#         ds_alpha.to_parquet(file_name=ds.name+\"_series_alpha\", root_dir=\"data\")\n",
    "        ds_omega.to_parquet(file_name=ds.name+\"_series_omega\", root_dir=\"data\")\n",
    "#         ds_theta.to_parquet(file_name=ds.name+\"_series_theta\", root_dir=\"data\")\n",
    "        \n",
    "    return ds_alpha, ds_omega, ds_theta\n",
    "\n",
    "#https://open.spotify.com/track/1ibeKVCiXORhvUpMmtsQWq?si=fVJAVtOtTHmZm0KPglam-w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = DataSetFX.from_parquet(root_dir=\"data/AttitudeTrajectoryProblem2D_C1_R1\", file_name=\"dataSet2_gridSampled_6.parquet\")\n",
    "# # print(len(ds))\n",
    "# # print(len(ds))\n",
    "# reference_time = 6529.276071694349\n",
    "# n_t_samples = 652\n",
    "# init_theta = -3.141592653589793\n",
    "\n",
    "# ds_alpha, ds_omega, ds_theta = convert_rotational_eom_to_solution_series(ds, init_theta, n_t_samples, reference_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Args:\n",
    "- in_channels (int): Number of channels in the input image\n",
    "- out_channels (int): Number of channels produced by the convolution\n",
    "- kernel_size (int or tuple): Size of the convolving kernel\n",
    "- stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
    "- padding (int or tuple, optional): Zero-padding added to both sides of the input. Default: 0\n",
    "- padding_mode (string, optional). Accepted values `zeros` and `circular` Default: `zeros`\n",
    "- dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
    "- groups (int, optional): Number of blocked connections from input channels to output channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.surrogate.modules import *\n",
    "from src.surrogate.deeplearning.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test case 1\n",
    "\n",
    "transform\n",
    "\n",
    "Data:\n",
    "- F = F, X = Theta\n",
    "- \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "tf1 = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "tx2 = preprocessing.StandardScaler()\n",
    "\n",
    "transform = TransformDataFrame.from_ordered_dict(OrderedDict([\n",
    "    (\"tf1\", (tf1, [\"f1\", \"f2\", \"f3\", \"f4\", 'f5'])),\n",
    "    (\"tx1\", (tx2, [f\"x{i}\" for i in range(1,653)]))\n",
    "#     (\"tx1\", (tx2, [f\"x{i}\" for i in range(652)])),\n",
    "]\n",
    "))\n",
    "# NB10422645 (Stage - Airbus)/data/\n",
    "ds_t1_theta = DataSetFSeries.from_parquet(root_dir=\"data\", file_name=\"dataSet2_gridSampled_6_series_omega\", transform=transform)\n",
    "\n",
    "# Define training function.\n",
    "def train_model(name, ds, model, model_folder, lr=1e-1, epoch=50, load=False, scheduler=None):\n",
    "    trainer = Trainer(model_folder, ds, model, torch.optim.Adam, torch.nn.MSELoss, num_epochs=epoch, batch_size=int(1e2), learning_rate=lr)\n",
    "    if scheduler is not None:\n",
    "        trainer.add_scheduler(torch.optim.lr_scheduler.MultiStepLR, milestones=scheduler[0], gamma=scheduler[1])\n",
    "    if load:\n",
    "        trainer.load_checkpoint(model_folder)\n",
    "    trainer.train()\n",
    "    return trainer._model\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "    \n",
    "class Flatten2(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), 1, -1)\n",
    "    \n",
    "class Unflatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), input.size(1), 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Sequential(\n",
      "  (0): Flatten2()\n",
      "  (1): Conv1d(1, 126, kernel_size=(72,), stride=(4,))\n",
      "  (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  (3): MaxPool1d(kernel_size=11, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): Conv1d(126, 258, kernel_size=(19,), stride=(1,), padding=(9,))\n",
      "  (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  (6): MaxPool1d(kernel_size=4, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (7): Conv1d(258, 258, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (8): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  (9): MaxPool1d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv1d(258, 126, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (11): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  (12): MaxPool1d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (13): Flatten()\n",
      "  (14): Linear(in_features=504, out_features=504, bias=True)\n",
      "  (15): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  (16): Linear(in_features=504, out_features=504, bias=True)\n",
      "  (17): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  (18): Linear(in_features=504, out_features=5, bias=True)\n",
      "  (19): Unflatten()\n",
      ")\n",
      "Epoch [  1  / 50  ]  |  Train Loss:  0.010362  |  Test Loss:  0.005148  |  lr:  0.00100\n",
      "Epoch [  2  / 50  ]  |  Train Loss:  0.005039  |  Test Loss:  0.004922  |  lr:  0.00100\n",
      "Epoch [  3  / 50  ]  |  Train Loss:  0.004688  |  Test Loss:  0.004838  |  lr:  0.00100\n",
      "Epoch [  4  / 50  ]  |  Train Loss:  0.004234  |  Test Loss:  0.004295  |  lr:  0.00010\n",
      "Epoch [  5  / 50  ]  |  Train Loss:  0.004174  |  Test Loss:  0.004361  |  lr:  0.00010\n",
      "Epoch [  6  / 50  ]  |  Train Loss:  0.004139  |  Test Loss:  0.004182  |  lr:  0.00010\n",
      "Epoch [  7  / 50  ]  |  Train Loss:  0.004106  |  Test Loss:  0.004399  |  lr:  0.00010\n",
      "Epoch [  8  / 50  ]  |  Train Loss:  0.004062  |  Test Loss:  0.004138  |  lr:  0.00010\n",
      "Epoch [  9  / 50  ]  |  Train Loss:  0.004008  |  Test Loss:  0.004181  |  lr:  0.00010\n",
      "Epoch [ 10  / 50  ]  |  Train Loss:  0.003955  |  Test Loss:  0.003829  |  lr:  0.00010\n",
      "Epoch [ 11  / 50  ]  |  Train Loss:  0.003902  |  Test Loss:  0.003998  |  lr:  0.00010\n",
      "Epoch [ 12  / 50  ]  |  Train Loss:  0.003845  |  Test Loss:  0.004101  |  lr:  0.00010\n",
      "Epoch [ 13  / 50  ]  |  Train Loss:  0.003786  |  Test Loss:  0.004051  |  lr:  0.00010\n",
      "Epoch [ 14  / 50  ]  |  Train Loss:  0.003726  |  Test Loss:  0.003733  |  lr:  0.00010\n",
      "Epoch [ 15  / 50  ]  |  Train Loss:  0.003687  |  Test Loss:  0.003957  |  lr:  0.00010\n",
      "Interrupted\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ggarrett/anaconda3/envs/py37/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "name = \"experiment1_series\"\n",
    "folder = f\"models/{name}\"\n",
    "\n",
    "ds = ds_t1_theta\n",
    "# print(ds.get_df())\n",
    "\n",
    "# model1 = nn.Sequential(\n",
    "#     BasicBlock(input_size=1, output_size=50, kernel_size=(1, 10), stride=2),\n",
    "#     torch.nn.MaxPool2d((1, 50), stride=1, padding=0, dilation=1, return_indices=False, ceil_mode=False),\n",
    "# #     ResidualBlock(hidden_size=50, kernel_size=(1,10), stride=1),\n",
    "# #     BasicBlock(input_size=20, output_size=10, kernel_size=(1, 20), stride=1),\n",
    "# #     torch.nn.MaxPool2d((1, 10), stride=1, padding=0, dilation=1, return_indices=False, ceil_mode=False),\n",
    "# #     BasicBlock(input_size=10, output_size=5, kernel_size=(1, 10), stride=1),\n",
    "    \n",
    "#     Flatten(),\n",
    "#     nn.Conv2d(500, 50, 1),\n",
    "#     activation_dict[\"leaky_relu\"],\n",
    "#     RegressionOutput(50, 4),\n",
    "    \n",
    "# )\n",
    "\n",
    "model1 = nn.Sequential(\n",
    "    \n",
    "    nn.Conv2d(1, 64, stride=4, kernel_size=(1,36), padding=0),   # [64,   1, 155]\n",
    "    nn.LeakyReLU(negative_slope=0.01, inplace=True),             # \n",
    "    nn.MaxPool2d((1,11), stride=2, padding=(0,2)),               # [64,   1,  73]\n",
    "    \n",
    "    \n",
    "    nn.Conv2d(64, 128, stride=1, kernel_size=(1,19), padding=9), # [128,  1,  73]\n",
    "    nn.LeakyReLU(negative_slope=0.01, inplace=True),             # \n",
    "    nn.MaxPool2d((1,4), stride=3, padding=(0,2)),                # [128,  1,  24]\n",
    "    \n",
    "    nn.Conv2d(128,172, stride=1, kernel_size=(1,3), padding=1),  # [172,  1,  24]\n",
    "    nn.LeakyReLU(negative_slope=0.01, inplace=True),             # \n",
    "    nn.MaxPool2d((1,4), stride=2, padding=(0,2)),                # [172,  1,  11]\n",
    "    \n",
    "    nn.Conv2d(172,128, stride=1, kernel_size=(1,3), padding=1),  # [128,  1,  11]\n",
    "    nn.LeakyReLU(negative_slope=0.01, inplace=True),             # \n",
    "    nn.MaxPool2d((1,4), stride=2, padding=(0,2)),                # [128,  1,   5]\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    nn.Linear(4096, 4096),                                         # [,860]\n",
    "    nn.LeakyReLU(negative_slope=0.01, inplace=True),             # \n",
    "    \n",
    "    nn.Linear(4096, 4096),                                         # [,860]\n",
    "    nn.LeakyReLU(negative_slope=0.01, inplace=True),             # \n",
    "    \n",
    "    nn.Linear(4096, 4),\n",
    "    Unflatten()\n",
    "    )\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "    \n",
    "class Flatten2(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), 1, -1)\n",
    "    \n",
    "class Unflatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), input.size(1), 1, 1)\n",
    "\n",
    "\n",
    "model2 = nn.Sequential(\n",
    "    \n",
    "    Flatten2(),\n",
    "    \n",
    "    nn.Conv1d(1, 126, stride=4, kernel_size=72, padding=0),       # [64,   1, 155]\n",
    "    nn.LeakyReLU(negative_slope=0.01, inplace=True),             # \n",
    "    nn.MaxPool1d(11, stride=2, padding=0),                       # [64,   1,  73]\n",
    "    \n",
    "    nn.Conv1d(126, 258, stride=1, kernel_size=19, padding=9),     # [128,  1,  73]\n",
    "    nn.LeakyReLU(negative_slope=0.01, inplace=True),             # \n",
    "    nn.MaxPool1d(4, stride=3, padding=0),                        # [128,  1,  24]\n",
    "    \n",
    "    nn.Conv1d(258, 258, stride=1, kernel_size=3, padding=1),     # [172,  1,  24]\n",
    "    nn.LeakyReLU(negative_slope=0.01, inplace=True),             # \n",
    "    nn.MaxPool1d(4, stride=2, padding=0),                        # [172,  1,  11]\n",
    "    \n",
    "    nn.Conv1d(258,126, stride=1, kernel_size=3, padding=1),      # [128,  1,  11]\n",
    "    nn.LeakyReLU(negative_slope=0.01, inplace=True),             # \n",
    "    nn.MaxPool1d(4, stride=2, padding=0),                        # [128,  1,   5]\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    nn.Linear(504, 504),                                       # [,860]\n",
    "    nn.LeakyReLU(negative_slope=0.01, inplace=True),             # \n",
    "    \n",
    "    nn.Linear(504, 504),                                       # [,860]\n",
    "    nn.LeakyReLU(negative_slope=0.01, inplace=True),             # \n",
    "    \n",
    "    nn.Linear(504, 5),\n",
    "    Unflatten()\n",
    "    )\n",
    "\n",
    "\n",
    "print(model2)\n",
    "\n",
    "model = train_model(name, ds, model2, folder, load=False,\n",
    "           scheduler=([3], 0.1),\n",
    "           epoch=50,\n",
    "           lr=1e-3)\n",
    "# https://open.spotify.com/track/0rUNZQuYQvOz6A6zwyT6tM?si=6WSixNxgSfW2FTLLytNB8g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = list(model.children())[1].weight[0]\n",
    "print(len(x_.flatten()))\n",
    "print(list(model.children())[1].weight[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "count = 0\n",
    "for res in list(model.children())[1].weight[::1]:\n",
    "# res = .weight[0]\n",
    "    res2 = res.detach().cpu().numpy().flatten()\n",
    "    plt.figure(dpi=400, figsize=(10,2))\n",
    "    plt.axis('off')\n",
    "    imgplot = plt.imshow(np.tile(res2.reshape(1,-1),(1,1)), cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(model.children())[4].weight.shape)\n",
    "\n",
    "\n",
    "# for res in list(model.children())[4].weight[::2]:\n",
    "# # res = .weight[0]\n",
    "#     res2 = res.detach().cpu().numpy().flatten()\n",
    "#     plt.figure(dpi=400, figsize=(10,2))\n",
    "#     plt.axis('off')\n",
    "#     imgplot = plt.imshow(np.tile(res2.reshape(1,-1),(20,1)), cmap='gray')\n",
    "\n",
    "res = list(model.children())[14].weight.detach().cpu().numpy()[:,:,]\n",
    "\n",
    "# avg = np.mean(res, axis=2)\n",
    "print(res.shape)\n",
    "\n",
    "plt.figure(dpi=500, figsize=(10,2))\n",
    "plt.axis('off')\n",
    "# imgplot = plt.imshow(avg[np.mean(avg,axis=1).argsort()], cmap='gray')\n",
    "imgplot = plt.imshow(res, cmap='gray')\n",
    "\n",
    "\n",
    "print(avg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for res in avg:\n",
    "# res = .weight[0]\n",
    "#     res2 = res.detach().cpu().numpy().flatten()\n",
    "    plt.figure(dpi=400, figsize=(10,2))\n",
    "    plt.axis('off')\n",
    "    imgplot = plt.imshow(np.tile(res.reshape(1,-1),(1,1)), cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in list(model.children())[10].weight[::3]:\n",
    "# res = .weight[0]\n",
    "    res2 = res.detach().cpu().numpy().flatten()\n",
    "    plt.figure(dpi=400, figsize=(10,2))\n",
    "    plt.axis('off')\n",
    "    imgplot = plt.imshow(np.tile(res2.reshape(1,-1),(1,1)), cmap='gray')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
